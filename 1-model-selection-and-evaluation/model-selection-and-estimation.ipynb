{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmiYn8GyBqMtuPJWsPRIh/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shadowusr/ml-course-2022/blob/main/1-model-selection-and-evaluation/model-selection-and-estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model selection and estimation"
      ],
      "metadata": {
        "id": "VKaG03zEb4HB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Theory\n",
        "The task of choosing the best model and estimating model specs is one of the most important steps in solving almost any machine learning problem.\n",
        "\n",
        "Let's consider the most common model evaluation metrics:\n",
        "- **Accuracy**\n",
        "  \n",
        "  Accuracy tells you how many times the model was able to detect a specific category. It shows share of correct answers out of total answers count.\n",
        "  \n",
        "  $$Accuracy = \\frac{(TP+TN)}{(TP+FP+FN+TN)}$$\n",
        "- **Precision**\n",
        "  \n",
        "  Precision measures the model's accuracy in classifying a sample as positive.\n",
        "  $$Precision = \\frac{TP}{(TP+FP)}$$\n",
        "- **Recall**\n",
        "\n",
        "  Recall measure the model's ability to detect positive samples.\n",
        "  $$Recall = \\frac{TP}{(TP+FN)}$$\n",
        "- **Specificity**\n",
        "\n",
        "  Specificity is the proportion of true negatives that are correctly predicted by the model.\n",
        "  $$Specificity = \\frac{TN}{(TN+FP)}$$\n",
        "- **F1-score**\n",
        "\n",
        "  F1 is a harmonic mean of the precision and recall\n",
        "  $$F1\\ Score = \\frac{2*(Recall * Precision)}{(Recall + Precision)}$$\n",
        "- **AUC/ROC (Receiver Operatin Characteristics) curve**\n",
        "\n",
        "  AUC - ROC curve is a performance measurement for the classification problems at various threshold settings. ROC is a probability curve and AUC represents the degree or measure of separability. It tells how much the model is capable of distinguishing between classes.\n",
        "\n",
        "To calculate these metrics, various cross-validation approaches can be used. To name a few:\n",
        "- Leave-one-out\n",
        "- K-fold\n",
        "- Shuffle split\n",
        "\n",
        "The end goal of model selection and estimation process is to choose the best model out of multiple options."
      ],
      "metadata": {
        "id": "oFvU0aEijM9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom implementation\n",
        "Our approach to model selection and estimation is to implement a framework with the following features:\n",
        "- Easy configuration via file, configuration of dataset, models list and cross validation method\n",
        "- Sequentally evaluate every given model on the dataset, build confusion matrices and calculate key quality metrics\n",
        "- Print a human-readable report as table in the end\n",
        "\n",
        "Let's look at our main class that performs models evaluation:"
      ],
      "metadata": {
        "id": "K39khTrmjQ1G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-BplDV8bo08"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import LeaveOneOut, KFold, ShuffleSplit\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "class AutoML:\n",
        "    @staticmethod\n",
        "    def __get_metrics_by_class(confusion_matrix: np.array):\n",
        "        # A good article on confusion matrix:\n",
        "        # https://towardsdatascience.com/confusion-matrix-for-your-multi-class-machine-learning-model-ff9aa3bf7826\n",
        "        metrics = []\n",
        "        classes_count = confusion_matrix.shape[0]\n",
        "\n",
        "        for i in range(classes_count):\n",
        "            tp = confusion_matrix[i][i]\n",
        "            tn = np.sum(\n",
        "                np.delete(\n",
        "                    np.delete(confusion_matrix, i, 0),\n",
        "                    i, 1\n",
        "                )\n",
        "            )\n",
        "            fp = np.sum(np.delete(confusion_matrix[:, i], i, 0))\n",
        "            fn = np.sum(np.delete(confusion_matrix[i], i, 0))\n",
        "\n",
        "            metrics.append({\n",
        "                \"accuracy\": (tp + tn) / (tp + tn + fp + fn),\n",
        "                \"precision\": tp / (tp + fp),\n",
        "                \"recall\": tp / (tp + fn),\n",
        "                \"specificity\": tn / (tn + fp),\n",
        "                \"f1_score\": (2 * tp) / (2 * tp + fp + fn),\n",
        "            })\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    @staticmethod\n",
        "    def __get_average_metrics(metrics_by_class):\n",
        "        result = {}\n",
        "        metrics = [\"accuracy\", \"precision\", \"recall\", \"specificity\", \"f1_score\"]\n",
        "\n",
        "        for metric in metrics:\n",
        "            result[metric] = sum(item[metric] for item in metrics_by_class) / len(metrics_by_class)\n",
        "\n",
        "        return result\n",
        "\n",
        "    @staticmethod\n",
        "    def get_reports(config):\n",
        "        reports = []\n",
        "        X = config[\"dataset\"][\"samples\"]\n",
        "        y = config[\"dataset\"][\"labels\"]\n",
        "        y_count = len(set(y))\n",
        "\n",
        "        for model in config[\"models\"]:\n",
        "            start_time = timer()\n",
        "            print(f\"Evaluating model {model}\")\n",
        "\n",
        "            labels_dict = {k: v for v, k in enumerate(set(y))}\n",
        "            label_to_index = lambda labels: [labels_dict.get(label) for label in labels]\n",
        "\n",
        "            confusion_matrix = np.zeros((y_count, y_count))\n",
        "\n",
        "            split = None\n",
        "\n",
        "            if config[\"validation\"][\"method\"] == \"loo\":\n",
        "                loo = LeaveOneOut()\n",
        "                split = loo.split(X)\n",
        "            elif config[\"validation\"][\"method\"] == \"k_fold\":\n",
        "                kf = KFold(n_splits=config[\"validation\"][\"n_splits\"])  # 2\n",
        "                split = kf.split(X)\n",
        "            elif config[\"validation\"][\"method\"] == \"shuffle_split\":\n",
        "                rs = ShuffleSplit(\n",
        "                    n_splits=config[\"validation\"][\"n_splits\"],  # 5\n",
        "                    test_size=config[\"validation\"][\"test_size\"],  # 0.25\n",
        "                    random_state=0\n",
        "                )\n",
        "                split = rs.split(X)\n",
        "                pass\n",
        "\n",
        "            iteration = 0\n",
        "            for train_index, test_index in split:\n",
        "                print(f\"\\riteration: {iteration}\", end='')\n",
        "                X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
        "                y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
        "\n",
        "                # Calling fit() multiple times on the same model is fine:\n",
        "                # https://stackoverflow.com/questions/49841324/what-does-calling-fit-multiple-times-on-the-same-model-do\n",
        "                model.fit(X_train, y_train)\n",
        "\n",
        "                y_predicted = model.predict(X_test)\n",
        "                confusion_matrix[label_to_index(y_test), label_to_index(y_predicted)] += 1\n",
        "\n",
        "                iteration += 1\n",
        "\n",
        "            print(\"\\n\")\n",
        "            end_time = timer()\n",
        "\n",
        "            report = AutoML.__get_average_metrics(AutoML.__get_metrics_by_class(confusion_matrix))\n",
        "            report[\"time\"] = end_time - start_time\n",
        "\n",
        "            reports.append(report)\n",
        "\n",
        "        return reports\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's write a configuration file:"
      ],
      "metadata": {
        "id": "Jx9wBO2tk-zn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "__dir = os.path.dirname(os.path.realpath(__file__))\n",
        "\n",
        "__df = pd.read_csv(f'{__dir}/diabetes.csv', encoding='utf-8', header=None)\n",
        "__df.columns = [\n",
        "    \"TimesPregnant\",\n",
        "    \"PlasmaGlucoseConcentration\",\n",
        "    \"BloodPressure\",\n",
        "    \"SkinfoldThickness\",\n",
        "    \"Insulin\",\n",
        "    \"BodyMassIndex\",\n",
        "    \"DiabetesPedigreeFunction\",\n",
        "    \"Age\",\n",
        "    \"HasDiabetes\"\n",
        "]\n",
        "\n",
        "config = {\n",
        "    \"dataset\": {\n",
        "        \"samples\": __df.drop([\"HasDiabetes\"], axis=1),\n",
        "        \"labels\": __df.HasDiabetes,\n",
        "    },\n",
        "    \"validation\": {\n",
        "        \"method\": \"loo\"\n",
        "    },\n",
        "    \"models\": [\n",
        "        LogisticRegression(C=1, max_iter=500),\n",
        "        KNeighborsClassifier(3),\n",
        "        RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "    ]\n",
        "}\n"
      ],
      "metadata": {
        "id": "o62YLMDdlCXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And combine it all together in the main file:"
      ],
      "metadata": {
        "id": "Eo_n__AXlDna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from config import config\n",
        "from auto_ml import AutoML\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "\n",
        "reports = AutoML.get_reports(config)\n",
        "\n",
        "table = PrettyTable()\n",
        "\n",
        "table.field_names = [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"Specificity\", \"F1 Score\", \"Time (s)\"]\n",
        "for index, report in enumerate(reports):\n",
        "    table.add_row([\n",
        "        str(config[\"models\"][index]),\n",
        "        report[\"accuracy\"],\n",
        "        report[\"precision\"],\n",
        "        report[\"recall\"],\n",
        "        report[\"specificity\"],\n",
        "        report[\"f1_score\"],\n",
        "        report[\"time\"]\n",
        "    ])\n",
        "\n",
        "print(table)\n"
      ],
      "metadata": {
        "id": "nHQlWL-9lJpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's sample report:"
      ],
      "metadata": {
        "id": "vAu396F6lNTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "+----------------------------------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+\n",
        "|                                Model                                 |      Accuracy      |     Precision      |       Recall       |    Specificity     |      F1 Score      |      Time (s)     |\n",
        "+----------------------------------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+\n",
        "|                LogisticRegression(C=1, max_iter=500)                 | 0.7760416666666666 | 0.7612391193036354 | 0.7284477611940299 | 0.7284477611940299 | 0.7387982377739637 |    51.202216625   |\n",
        "|                 KNeighborsClassifier(n_neighbors=3)                  | 0.6940104166666666 | 0.6614952413714024 | 0.6576567164179105 | 0.6576567164179105 | 0.6593425053652423 | 8.434406150000001 |\n",
        "| RandomForestClassifier(max_depth=5, max_features=1, n_estimators=10) |        0.75        | 0.7357949218017478 | 0.6876716417910448 | 0.6876716417910448 | 0.698268876611418  |    30.257538501   |\n",
        "+----------------------------------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+"
      ],
      "metadata": {
        "id": "UvmJVsDElMVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TPOT\n",
        "The Tree-Based Pipeline Optimization Tool (TPOT) was one of the very first AutoML methods and open-source software packages developed for the data science community.\n",
        "\n",
        "The goal of TPOT is to automate the building of ML pipelines by combining a flexible expression tree representation of pipelines with stochastic search algorithms such as genetic programming. TPOT makes use of the Python-based scikit-learn library as its ML menu.\n",
        "\n",
        "<img src=\"http://automl.info/wp-content/uploads/2017/07/tpot-pipeline-example-768x361.png\">\n",
        "\n",
        "Let's try using TPOT for solving the iris flowers classification problem.\n",
        "\n"
      ],
      "metadata": {
        "id": "8tlBhlgGlafP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tpot import TPOTClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "iris = load_iris()\n",
        "iris.data[0:5], iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target,\n",
        "                                                    train_size=0.75, test_size=0.25)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
        "\n",
        "tpot = TPOTClassifier(verbosity=2, max_time_mins=2)\n",
        "tpot.fit(X_train, y_train)\n",
        "print(tpot.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "LPtLSkPSmgJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample output:"
      ],
      "metadata": {
        "id": "VdbrPYETm29P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Optimization Progress: 100%|██████████| 200/200 [00:18<00:00,  9.33pipeline/s]\n",
        "Generation 1 - Current best internal CV score: 0.9825757575757577\n",
        "Optimization Progress: 100%|██████████| 300/300 [00:28<00:00, 12.80pipeline/s]\n",
        "Generation 2 - Current best internal CV score: 0.9825757575757577\n",
        "Optimization Progress: 100%|██████████| 400/400 [00:39<00:00, 11.16pipeline/s]\n",
        "Generation 3 - Current best internal CV score: 0.990909090909091\n",
        "Optimization Progress: 100%|██████████| 500/500 [00:45<00:00, 17.87pipeline/s]\n",
        "Generation 4 - Current best internal CV score: 0.990909090909091\n",
        "Optimization Progress: 100%|██████████| 600/600 [00:52<00:00, 16.63pipeline/s]\n",
        "Generation 5 - Current best internal CV score: 0.990909090909091\n",
        "Optimization Progress: 100%|██████████| 700/700 [00:58<00:00, 17.42pipeline/s]\n",
        "Generation 6 - Current best internal CV score: 0.990909090909091\n",
        "Optimization Progress: 100%|██████████| 800/800 [01:06<00:00, 14.45pipeline/s]\n",
        "Generation 7 - Current best internal CV score: 0.990909090909091\n",
        "Optimization Progress: 100%|██████████| 900/900 [01:11<00:00, 12.45pipeline/s]\n",
        "Generation 8 - Current best internal CV score: 0.990909090909091\n",
        "Optimization Progress: 100%|██████████| 1000/1000 [01:17<00:00,  8.87pipeline/s]\n",
        "Generation 9 - Current best internal CV score: 0.990909090909091\n",
        "Optimization Progress: 100%|██████████| 1100/1100 [01:23<00:00, 11.12pipeline/s]\n",
        "Generation 10 - Current best internal CV score: 0.990909090909091\n",
        "Optimization Progress: 100%|██████████| 1200/1200 [01:29<00:00,  9.37pipeline/s]\n",
        "Generation 11 - Current best internal CV score: 0.990909090909091\n",
        "Optimization Progress: 100%|██████████| 1300/1300 [01:34<00:00,  9.55pipeline/s]\n",
        "Generation 12 - Current best internal CV score: 0.990909090909091\n",
        "Optimization Progress: 100%|██████████| 1400/1400 [01:40<00:00, 16.09pipeline/s]\n",
        "Generation 13 - Current best internal CV score: 0.990909090909091\n",
        "Optimization Progress: 100%|██████████| 1500/1500 [01:46<00:00,  9.96pipeline/s]\n",
        "Generation 14 - Current best internal CV score: 0.990909090909091\n",
        "Optimization Progress: 100%|██████████| 1600/1600 [01:52<00:00, 10.02pipeline/s]\n",
        "Generation 15 - Current best internal CV score: 0.990909090909091\n",
        "Optimization Progress: 100%|██████████| 1700/1700 [01:59<00:00,  7.28pipeline/s]\n",
        "Generation 16 - Current best internal CV score: 0.990909090909091\n",
        "                                                                                \n",
        "TPOT closed prematurely. Will use the current best pipeline.\n",
        "\n",
        "Best pipeline: DecisionTreeClassifier(RBFSampler(input_matrix, RBFSampler__gamma=0.85), DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=3, DecisionTreeClassifier__min_samples_leaf=4, DecisionTreeClassifier__min_samples_split=9)\n",
        "0.973684210526"
      ],
      "metadata": {
        "id": "Elxs2fC1m4Pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## auto-sklearn\n",
        "auto-sklearn is an automated machine learning toolkit and a drop-in replacement for a scikit-learn estimator. auto-sklearn frees a machine learning user from algorithm selection and hyperparameter tuning. It leverages recent advantages in Bayesian optimization, meta-learning and ensemble construction.\n",
        "\n",
        "Let's apply auto-sklearn to the breast cancer classification problem."
      ],
      "metadata": {
        "id": "e7MNdDc4leoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "import sklearn.datasets\n",
        "import sklearn.metrics\n",
        "\n",
        "import autosklearn.classification\n",
        "\n",
        "X, y = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = \\\n",
        "    sklearn.model_selection.train_test_split(X, y, random_state=1)\n",
        "\n",
        "automl = autosklearn.classification.AutoSklearnClassifier(\n",
        "    time_left_for_this_task=120,\n",
        "    per_run_time_limit=30,\n",
        "    tmp_folder='/tmp/autosklearn_classification_example_tmp',\n",
        ")\n",
        "automl.fit(X_train, y_train, dataset_name='breast_cancer')"
      ],
      "metadata": {
        "id": "1MinShT3nqym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can conveniently view models scoreboard:"
      ],
      "metadata": {
        "id": "2P4AGI0Gn252"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(automl.leaderboard())\n",
        "\n",
        "# Outputs:\n",
        "          rank  ensemble_weight                 type      cost  duration\n",
        "model_id\n",
        "7            1             0.08          extra_trees  0.014184  1.386039\n",
        "16           2             0.06    gradient_boosting  0.021277  0.908949\n",
        "21           3             0.02          extra_trees  0.021277  1.240055\n",
        "2            4             0.04        random_forest  0.028369  1.507876\n",
        "3            5             0.06                  mlp  0.028369  0.819861\n",
        "22           6             0.02    gradient_boosting  0.028369  0.976891\n",
        "10           7             0.06        random_forest  0.028369  1.648257\n",
        "11           8             0.04        random_forest  0.028369  1.878659\n",
        "13           9             0.04    gradient_boosting  0.028369  1.238531\n",
        "26          10             0.06          extra_trees  0.028369  2.249340\n",
        "19          11             0.08          extra_trees  0.028369  2.809216\n",
        "27          12             0.06          extra_trees  0.028369  7.942544\n",
        "8           13             0.02        random_forest  0.035461  1.692722\n",
        "17          14             0.02    gradient_boosting  0.035461  1.413625\n",
        "25          15             0.02             adaboost  0.042553  1.828053\n",
        "9           16             0.02          extra_trees  0.042553  1.613578\n",
        "30          17             0.04             adaboost  0.049645  0.595418\n",
        "34          18             0.04          extra_trees  0.049645  1.247910\n",
        "23          19             0.02                  mlp  0.049645  1.978261\n",
        "15          20             0.04                  mlp  0.049645  3.234449\n",
        "33          21             0.06        decision_tree  0.056738  0.868145\n",
        "31          22             0.02          gaussian_nb  0.056738  0.643746\n",
        "24          23             0.02        random_forest  0.070922  1.500164\n",
        "20          24             0.04   passive_aggressive  0.078014  0.634079\n",
        "32          25             0.02  k_nearest_neighbors  0.092199  0.678369"
      ],
      "metadata": {
        "id": "E-4F52iwn8gB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To view the final machine learning algorithms ensemble generated by auto-sklearn, we can do the following:"
      ],
      "metadata": {
        "id": "tuz9Em6-oJqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(automl.show_models(), indent=4)\n",
        "\n",
        "# Outputs:\n",
        "{   2: {   'balancing': Balancing(random_state=1),\n",
        "           'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7fb0ef3fef10>,\n",
        "           'cost': 0.028368794326241176,\n",
        "           'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7fb0ef79d3d0>,\n",
        "           'ensemble_weight': 0.04,\n",
        "           'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7fb0ef3fea60>,\n",
        "           'model_id': 2,\n",
        "           'rank': 4,\n",
        "           'sklearn_classifier': RandomForestClassifier(max_features=5, n_estimators=512, n_jobs=1,\n",
        "                       random_state=1, warm_start=True)},\n",
        "    3: {   'balancing': Balancing(random_state=1),\n",
        "           'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7fb0edc49430>,\n",
        "           'cost': 0.028368794326241176,\n",
        "           'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7fb0ef2df100>,\n",
        "           'ensemble_weight': 0.06,\n",
        "           'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7fb0edc491f0>,\n",
        "           'model_id': 3,\n",
        "           'rank': 5,\n",
        "           'sklearn_classifier': MLPClassifier(activation='tanh', alpha=0.0001363185819149026, beta_1=0.999,\n",
        "              beta_2=0.9, early_stopping=True,\n",
        "              hidden_layer_sizes=(115, 115, 115),\n",
        "              learning_rate_init=0.00018009776276177523, max_iter=32,\n",
        "              n_iter_no_change=32, random_state=1, verbose=0, warm_start=True)},\n",
        "    ..."
      ],
      "metadata": {
        "id": "R0SX2ZcfoTbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's get the score of the final ensemble:"
      ],
      "metadata": {
        "id": "GXF2Wp-Moc83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = automl.predict(X_test)\n",
        "print(\"Accuracy score:\", sklearn.metrics.accuracy_score(y_test, predictions))\n",
        "# Outputs:\n",
        "Accuracy score: 0.958041958041958"
      ],
      "metadata": {
        "id": "aCFDjGe4ofPJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}